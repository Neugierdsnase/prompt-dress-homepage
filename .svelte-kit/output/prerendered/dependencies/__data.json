{"type":"data","nodes":[null,null,{"type":"data","data":[{"features":1,"posts":39,"socialProofs":99},[2,7,12,19,24,32],{"name":3,"description":4,"image":5,"tags":6},"\u003Cb>Free.\u003C/b>\u003Cbr>No credit card required.\u003Cbr>Not even an email address.","All features you see on this website are free and will remain so. If you want network or enterprise features, please \u003Ca href=\"mailto: prompt-dress@vomkonstant.in\" target=\"_blank\" /> contact me via email\u003C/a>.","images/cyberpunk/coffee_small.png",[],{"name":8,"description":9,"image":10,"tags":11},"100% Compliant","No data gets sent anywhere from the browser extension. Everything is saved locally on your computer.","images/cyberpunk/handshake_small.png",[],{"name":13,"description":14,"image":15,"tags":16},"Multi-Step Priming and Prompting","With the \u003Cb>\"Shawl\"\u003C/b> feature (in active development), you can prime the model in multiple steps. Making it easier to get the model to stick to a certain schema or template.","images/cyberpunk/shawl.png",[17],{"label":18},"On the way",{"name":20,"description":21,"image":22,"tags":23},"Dynamic values","No more manually searching for words or phrases you need to adjust for the occasion. The \u003Cb>\"Corsages\"\u003C/b> feature allows you to dynamically change values in the prompt before feeding it to the model.","images/cyberpunk/corsage.png",[],{"name":25,"description":26,"image":27,"tags":28},"Versioning","Do you want to iterate over an old version of your prompt because it stopped working, but you don't want to delete it. No problem, just use the versioning feature (actively being developed).","images/cyberpunk/tailor.png",[29],{"label":30,"color":31},"Next on the Roadmap","secondary",{"name":33,"description":34,"image":35,"tags":36},"Tags and Filters","Organize your prompts in a straightforward manner, not more sifting through folders and text files.","images/cyberpunk/wip_dress.png",[37],{"label":38,"color":31},"Coming Soon",[40,89,94],{"slug":41,"title":42,"date":43,"excerpt":44,"coverImage":45,"tags":46,"keywords":49,"html":55,"readingTime":56,"relatedPosts":57},"prompt-engineering-for-language-learners","Prompt Engineering for language learners","2023-10-10T13:55:21.800Z","Learn how to prime ChatGPT so you can use it as a conversational partner for practicing second languages","/images/cyberpunk/conversation.png",[47,48],"prompt engineering","language learning",[47,48,50,51,52,53,54],"large language model","LLM","prompting","generative AI","ChatGPT","\u003Cp>If you want to learn a language, a plethora of apps, websites, books, and podcasts can help you. With the rising proficiency of Large Language Models, a new player entered the game.\u003C/p>\n\u003Cp>ChatGPT is, as of writing these lines, the uncontested champion of Large Language Models, due to large parts just the sheer volume of input it was given as training data. As this training data was pretty much the whole internet of the last ten years, it includes text in many different languages. This means that it is well-trained not only in English but also in languages contained sufficiently within the training data.\u003C/p>\n\u003Ch2 id=\"hey-computer-have-a-conversation-with-me\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#hey-computer-have-a-conversation-with-me\">\u003Cspan>#\u003C/span>\u003C/a>Hey Computer, have a conversation with me\u003C/h2>\n\u003Cp>By default, ChatGPT is not really in conversation mode. It will not prompt you back and request more information from you. It will try to answer the question as well as possible with the information given and consider its job done.\u003C/p>\n\u003Cimg src=\"https://media1.giphy.com/media/3adl5Cc0CsbfEH3l5E/giphy.gif?cid=ecf05e47ndoegrln27zeuor8gsfxz4s7t4ni2yg0mpkltdaj&ep=v1_gifs_related&rid=giphy.gif&ct=g\" alt=\"A gif showing a woman ending a conversation decisively\">\n\u003Cp>This is where prompt engineering comes in. For situations when I want to enter \u003Cem>“conversation mode”\u003C/em> with an LLM, there is a magic phrase I like to use right in my first prompt:\u003C/p>\n\u003Cblockquote>\u003Cp>I want you to end every answer with a question.\u003C/p>\u003C/blockquote>\n\u003Cp>This ensures that the conversation never dries up, and ChatGPT continues it by inquiring more about the topic. Let’s pretend we want to learn English for the sake of this article. Let’s define the conversation we want to have with the AI.\u003C/p>\n\u003Cp>These are the parameters and boundaries I want to set for the conversation:\u003C/p>\n\u003Cul>\u003Cli>The language and words used should correspond to your current level.\u003C/li>\n\u003Cli>The topics should be constrained to the ones I am already familiar with.\u003C/li>\n\u003Cli>It should not tolerate grammatical errors and typos as it usually would\u003C/li>\n\u003Cli>and as mentioned above, keep the conversation flowing by ending responses with a question.\u003C/li>\u003C/ul>\n\u003Ch2 id=\"drafting-the-prompt\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#drafting-the-prompt\">\u003Cspan>#\u003C/span>\u003C/a>Drafting the prompt\u003C/h2>\n\u003Cp>Let’s start with a general sentence that sets the primary setting for our conversation.\u003C/p>\n\u003Cblockquote>\u003Cp>I want to learn German, and I want to practice my conversational skills with you.\u003C/p>\u003C/blockquote>\n\u003Cp>The stage is set, so far, so good. Now, let’s go through the points above and formulate them as concisely and precisely as possible.\u003C/p>\n\u003Cblockquote>\u003Cp>I am currently on the B1 level…\u003C/p>\u003C/blockquote>\n\u003Cp>The categorization of language skills according to the \u003Ca href=\"https://en.wikipedia.org/wiki/Common_European_Framework_of_Reference_for_Languages\" rel=\"nofollow\">“Common European Framework of Reference for Languages”\u003C/a> is a widely accepted and used standard for classifying language skills and thus is well within ChatGPT’s knowledge. Let’s continue:\u003C/p>\n\u003Cblockquote>\u003Cp>I am currently on the B1 level, and the topics I am comfortable with are hobbies and outside activities.\u003C/p>\u003C/blockquote>\n\u003Cp>For the next point, we should ask it to be strict with us but to keep the corrections positive so we don’t demotivate ourselves.\u003C/p>\n\u003Cblockquote>\u003Cp>Strictly correct any grammatical errors or typos I might make and point them out in an understanding and encouraging tone.\u003C/p>\u003C/blockquote>\n\u003Cp>For the last point, we should consider not only asking for a question at the end but also telling the model the reason for our request, giving it more context. It may then - for example - opt for an open-ended instead of a closed-ended question.\u003C/p>\n\u003Cblockquote>\u003Cp>End every reply with a question to keep the conversation flowing.\u003C/p>\u003C/blockquote>\n\u003Cp>So there we have it. Our complete prompt now reads:\u003C/p>\n\u003Cblockquote>\u003Cp>I want to learn German, and I want to practice my conversational skills with you. I am currently on the B1 level, and the topics I am comfortable with are hobbies and outside activities. Strictly correct any grammatical errors or typos that I might make and point them out to me in an understanding and encouraging tone. End every reply with a question to keep the conversation flowing.\u003C/p>\u003C/blockquote>\n\u003Cp>Here is a screenshot of how that worked out for me. I deliberately conversed with a bunch of different mistakes (German is actually my first language), and every correction that ChatGPT offered was spot on. It even used encouraging phrases like \u003Cem>“fast perfekt”\u003C/em> (“almost perfect”) when correcting my mistakes. The questions it offers in return are very much on topic, while the words used are easy, and the structure of the sentences is simple.\u003C/p>\n\u003Cimg src=\"https://i.imgur.com/qQTXsOC.png\" alt=\"The conversation I had with ChatGPT after using the prompt we just created.\">\n\u003Ch2 id=\"variations-of-the-prompt\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#variations-of-the-prompt\">\u003Cspan>#\u003C/span>\u003C/a>Variations of the prompt\u003C/h2>\n\u003Cp>It is important to remember that the same prompt with only slightly different formulations and words can impact the replies we get from the AI. Take this prompt, for example, where I have expressed the same sentiment. Still, the model seems to think there is a need to appear more whimsical and use emotes, nothing I explicitly specified.\u003C/p>\n\u003Cimg src=\"https://i.imgur.com/QH2lREX.png\" alt=\"The conversation I had with ChatGPT after using the prompt we just created.\">\n\u003Cp>Since it is not immediately apparent to us as humans what the second prompt has caused - among other minor changes - the use of emotes, it is crucial to save the prompts that yield results we are satisfied with.\u003C/p>\n\u003Ch2 id=\"saving-the-prompt\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#saving-the-prompt\">\u003Cspan>#\u003C/span>\u003C/a>Saving the prompt\u003C/h2>\n\u003Cp>Now, how do we save the prompt so we don’t need to redo all the work we did every time we wanted a little language-learning session?\u003C/p>\n\u003Cp>Well, here is where [this browser extension] comes into play. It allows us to save prompts right in our browser so we always have them ready for use.\u003C/p>\n\u003Cp>\u003Cem>Disclaimer: I am the one-man show behind this browser extension, so this is my plug for the thing. It would really mean a lot to me if you checked it out and shot some feedback my way!\u003C/em>\u003C/p>\n\u003Cimg src=\"https://c4.wallpaperflare.com/wallpaper/89/9/256/movie-puss-in-boots-wallpaper-thumb.jpg\" alt=\"Puss in Boots making puppy eyes.\">\n\u003Cp>Here is the even cooler part: If you want to keep some parts of the prompt changeable, you can put a placeholder in the text (and still maintain a default value).\u003C/p>\n\u003Cp>Here is what our prompt looks like, but with dynamic values for the language you want to practice, your level, and the topics you are familiar with.\u003C/p>\n\u003Cimg src=\"https://i.imgur.com/KA5YTA1.png\" alt=\"The conversation I had with ChatGPT after using the prompt we just created.\">\n\u003Cp>Pretty cool, huh? And one more thing: If you download the extension now, you will find that this very prompt is already in there as one of the example prompts!\u003C/p>\n\u003Cp>There is even more to this, but that can be better shown in a video, which is why I will upload tutorials with this kind of content to \u003Ca href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" rel=\"nofollow\">this channel\u003C/a>. \u003Ca href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" rel=\"nofollow\">Subscribe now\u003C/a> if you want to see me craft real-time prompts!\u003C/p>\n\u003Cp>Please let me know if you found this helpful via the appropriate buttons or commenting. Suppose you are falling in love with the extension and want to keep up to date with its development. In that case, the best way is by \u003Ca href=\"https://medium.com/@k8603427\" rel=\"nofollow\">following me on Medium\u003C/a>, \u003Ca href=\"https://prompt-dress.vomkonstant.in/p/5f693fe8-6f20-4796-b0dc-8d3848e591a0\" rel=\"nofollow\">signing up for my email newsletter\u003C/a>, or \u003Ca href=\"https://prompt-dress.com/blog\" rel=\"nofollow\">following this blog.\u003C/a>\u003C/p>\n\u003Cp>A version of this article has been posted \u003Ca href=\"https://medium.com/@k8603427\" rel=\"nofollow\">to my Medium account.\u003C/a>\u003C/p>","6 min read",[58,69,78],{"slug":59,"title":60,"date":61,"excerpt":62,"coverImage":63,"tags":64,"keywords":66,"html":67,"readingTime":68},"prompt-engineering-basics","Improving Conversations with Computers: A Simple Guide to Prompt Engineering","2023-09-29T13:55:21.800Z","Explore the basics of prompt engineering and improve your interactions with Large Language Models (LLMs). Learn how crafting the right prompts can lead to better responses in this simple guide.","/images/cyberpunk/tailor.png",[47,65],"basics",[47,50,51,52,53,54],"\u003Ch2 id=\"introduction\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#introduction\">\u003Cspan>#\u003C/span>\u003C/a>Introduction\u003C/h2>\n\u003Cp>Getting the right responses from Large Language Models (LLMs) like GPT-3 often comes down to asking the right way. This process of crafting questions or statements to get desired answers is called prompt engineering. In this blog post, we’ll explore what prompt engineering is, and how it can help us interact better with language models.\u003C/p>\n\u003Ch2 id=\"getting-started\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#getting-started\">\u003Cspan>#\u003C/span>\u003C/a>Getting Started\u003C/h2>\n\u003Cp>Prompt engineering starts with understanding what you want to achieve. Whether you want to create imaginative text, get answers to specific questions, or have the model complete your sentences, knowing your goal is the first step. Once that’s clear, you can start creating prompts that will lead to the responses you want.\u003C/p>\n\u003Ch2 id=\"how-to-create-good-prompts\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#how-to-create-good-prompts\">\u003Cspan>#\u003C/span>\u003C/a>How to Create Good Prompts\u003C/h2>\n\u003Cp>Creating good prompts is part science, part art. It requires thinking about what the language model can and can’t do while making your requests. Here are some tips:\u003C/p>\n\u003Col>\u003Cli>\u003Cstrong>Be Clear\u003C/strong>: Your prompt should be clear and to the point, to guide the LLM toward the result you want. If your prompt is vague, you might get answers you didn’t expect.\u003C/li>\n\u003Cli>\u003Cstrong>Provide Context\u003C/strong>: Including some relevant information can help the LLM understand better what you’re asking for. This way, you’re likely to get more accurate responses.\u003C/li>\n\u003Cli>\u003Cstrong>Experiment with Length and Structure\u003C/strong>: The way you structure your prompt, and how long or short it is, can affect the answers you get. Feel free to try different approaches to see what works best.\u003C/li>\n\u003Cli>\u003Cstrong>Keep Improving\u003C/strong>: Prompt engineering isn’t a one-time task. It’s about trying different things, seeing what works, and refining your prompts based on what you learn.\u003C/li>\u003C/ol>\n\u003Ch2 id=\"conclusion\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#conclusion\">\u003Cspan>#\u003C/span>\u003C/a>Conclusion\u003C/h2>\n\u003Cp>Prompt engineering is a handy skill when working with language models. By learning how to craft effective prompts, we can have better interactions with these models. So, the next time you work with an LLM, take some time to think about your prompts, experiment, and see how the right prompt can lead to better results.\u003C/p>","2 min read",{"slug":70,"title":71,"date":72,"excerpt":62,"coverImage":73,"tags":74,"keywords":75,"html":76,"readingTime":77},"prompt-engineering-for-real-estate-listings","Prompt Engineering: A real life example EVERYONE can use (but I'm using real estate as an example)","2023-10-07T08:11:21.800Z","/images/cyberpunk/real-estate.png",[47,65],[47,50,51,52,53,54],"\u003Cp>There are plenty of use cases for ChatGPT. What makes it such a powerful tool is that it’s so easy to use. You type in a question, and you get an impressive answer.\u003C/p>\n\u003Cp>There is a difference, however, between a result that is impressive because we are not used to computers being able to generate natural text this way and results that are useful to the person asking. I’ll give you an example.\u003C/p>\n\u003Cimg src=\"https://i.imgflip.com/8193r0.jpg\" alt=\"Meme from American Psycho: Impressive, very nice, now show me what you are actually using it for.\">\n\u003Cp>Large Language Models are impressive, but that doesn’t always mean they are useful.\u003C/p>\n\u003Cp>I sometimes meet a realtor at the gym. He knows I’m a software engineer, and we sometimes ask questions about each other’s professions. I inquire about the real estate market, and he about software. At one point, we were talking about ChatGPT, and I’m paraphrasing his take on it:\u003C/p>\n\u003Cblockquote>\u003Cp>\u003Cem>It’s good and really impressive what it can do, and I tried to generate some text for listings with it. However, the results are just not quite there yet, so I still have to go back and change a lot of stuff, which is the same amount of work as just writing it myself.\u003C/em>\u003C/p>\u003C/blockquote>\n\u003Cp>While I get the sentiment, it’s probably not an entirely fair point since most people expect the model to return results based partly on information they don’t have - like the style, tone and structure you prefer.\u003C/p>\n\u003Cp>This is why prompt engineering is relevant and \u003Ca href=\"https://futurism.com/prompt-engineers-ai\" rel=\"nofollow\">prompt engineers\u003C/a> are \u003Ca href=\"https://www.thehindu.com/sci-tech/technology/are-prompt-engineers-still-in-demand/article67361444.ece\" rel=\"nofollow\">(still)\u003C/a> \u003Ca href=\"https://www.msn.com/en-in/money/topstories/prompt-engineer-is-the-hottest-new-job-see-qualifications-and-salary-details/ar-AA1gECrW\" rel=\"nofollow\">in demand\u003C/a>. So, let’s take this very use case, and unravel how a prompt engineer might tackle this task step-by-step.\u003C/p>\n\u003Cimg src=\"https://media.giphy.com/media/zaezT79s3Ng7C/giphy.gif\" alt=\"\">\n\u003Ch2 id=\"setting-the-right-context\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#setting-the-right-context\">\u003Cspan>#\u003C/span>\u003C/a>Setting the right context\u003C/h2>\n\u003Cp>First off, we need to set the proper context. A popular way to do this is to propose a role play, asking ChatGPT to take on the role of a competent and knowledgeable counterpart. This is an example of this:\u003C/p>\n\u003Cp>\u003Cem>“You are a realtor writing copy for the new listing they want to sell or rent. You have a specific structure you always want to adhere to and a specific tone in which you like these texts to be written.\u003C/em>\u003C/p>\n\u003Cp>\u003Cem>I will give examples of text I like, and I want you to reproduce their structure and tone with the information about the new objects I will provide you afterwards.”\u003C/em>\u003C/p>\n\u003Cp>If we submit the prompt like this, the model will respond by reiterating the key points of the prompt, which is unnecessary, so I like to end all my “priming” prompts with: \u003Cem>“If you understand, just reply with READ.”\u003C/em>\u003C/p>\n\u003Cp>\u003Cstrong>Side note:\u003C/strong> This also conveniently \u003Ca href=\"https://www.aidare.com/what-are-tokens-and-their-role-in-chatgpt/\" rel=\"nofollow\">saves us some tokens.\u003C/a>\u003C/p>\n\u003Cp>Perfect, so now we have the initial prompt set up, and we might need to come back to it later and tweak it a bit. Still, it is a great start, so I will save that prompt into my \u003Ca href=\"https://chrome.google.com/webstore/detail/prompt-dress/mpcinhhegdohpapgmiopjlfhemhhfmid\" rel=\"nofollow\">Prompt Dress browser extension\u003C/a> so that I always have it ready the next time I need it.\u003C/p>\n\u003Ch2 id=\"adding-templates-to-let-the-ai-know-the-style-we-like\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#adding-templates-to-let-the-ai-know-the-style-we-like\">\u003Cspan>#\u003C/span>\u003C/a>Adding templates to let the AI know the style we like\u003C/h2>\n\u003Cp>Cool. Now, I will continue by pasting in some of the text I’d like ChatGPT to use as templates. So, I found these texts for some random London apartments online that I will use here. \u003Ca href=\"https://paste.bingner.com/paste/fsm22/raw\" rel=\"nofollow\">I pasted them in this bin so you can reproduce my workflow.\u003C/a>\u003C/p>\n\u003Cp>Alright, so I like to open the prompt with the disclaimer that this is one of the examples. I paste in the text, and then I end the prompt with something that will shorten the response again.\u003C/p>\n\u003Cp>Quick recap: The structure now is:\u003C/p>\n\u003Cp>\u003Cem>“This is one of the examples I would like you to follow.\u003C/em>\u003Cbr>\n\u003Cem>[one of the mentioned examples I put in this bin]\u003C/em>\u003Cbr>\n\u003Cem>If you understand, reply READ.”\u003C/em>\u003C/p>\n\u003Ch2 id=\"priming-done-lets-prompt\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#priming-done-lets-prompt\">\u003Cspan>#\u003C/span>\u003C/a>Priming done, let’s prompt\u003C/h2>\n\u003Cp>So, after this is done, it’s finally time to get to the good parts. We can consider our AI sufficiently primed for our use case and now prompt it for the task we want to perform. I tried this with the following made-up example.\u003C/p>\n\u003Cp>\u003Cem>“I now have a new listing with the following stats: 80 square meters plus 15 square meter balcony, location relatively central, but in a bad neighbourhood. Third floor. Bathroom and toilet separately. The main selling point is that it is bright. Generate a listing for this object.”\u003C/em>\u003C/p>\n\u003Cp>The result is spot-on. The text generated follows the templates given in structure and tone and cleverly describes the downsides positively. I would be confident that any real estate agent would be satisfied with the result as-is (provided the templates given are ones they like).\u003C/p>\n\u003Cp>Know that what I just showed you is a widespread technique used by many people to get the results they want, but since this worked so well, I now want to save the work I’ve done. Until now, this was mostly a matter of having some text files lying around somewhere, which quickly gets messy.\u003C/p>\n\u003Cp>That’s why I made a browser extension to tackle this problem, first for myself, then I decided to share it with you guys and called it “Prompt Dress”.\u003C/p>\n\u003Cp>Please let me know if you found this helpful via the appropriate buttons or commenting. If you are falling in love with the extension and want to keep up to date with its development, the best way is by \u003Ca href=\"https://medium.com/@k8603427\" rel=\"nofollow\">following me on Medium\u003C/a>, \u003Ca href=\"https://prompt-dress.vomkonstant.in/p/5f693fe8-6f20-4796-b0dc-8d3848e591a0\" rel=\"nofollow\">signing up for my email newsletter\u003C/a>, or \u003Ca href=\"https://prompt-dress.com/blog\" rel=\"nofollow\">following this blog.\u003C/a>\u003C/p>\n\u003Cp>A version of this article has been posted \u003Ca href=\"https://medium.com/@k8603427\" rel=\"nofollow\">to my Medium account.\u003C/a>\u003C/p>","5 min read",{"title":79,"slug":80,"coverImage":81,"date":82,"excerpt":83,"hidden":84,"tags":85,"html":87,"readingTime":88},"How Blog Posts Work","blog-posts","/images/posts/blog-posts.jpg","2023-04-22T21:55:15.361Z","How to manage existing blog posts and create new ones",true,[86],"Documentation","\u003Cp>All blog posts are located inside the \u003Ccode>src/routes/(blog-article)\u003C/code> folder. Each folder inside it represents a blog post, and each folder has a \u003Ccode>+page.md\u003C/code> file, which is the file that contains the post’s content.\u003C/p>\n\u003Cp>This way, the URL for each blog post is generated with the folder’s name. For example, the folder \u003Ccode>src/routes/(blog-article)/how-blog-posts-work\u003C/code> will generate the URL \u003Ccode>https://mysite.com/how-blog-posts-work\u003C/code>.\u003C/p>\n\u003Cp>All posts are Markdown files, which means you can use the \u003Ca href=\"https://www.markdownguide.org/basic-syntax\" rel=\"nofollow\">Markdown syntax\u003C/a> in them, and it will work out of the box. However, since this projects uses \u003Ca href=\"https://mdsvex.pngwn.io/\" rel=\"nofollow\">MDsveX\u003C/a> to parse Markdown, you can also use Svelte components inside them! This means that the components used in other pages can also be used in blog posts.\u003C/p>\n\u003Cdiv class=\"callout-block info svelte-sxx0n0\">\u003Cdiv class=\"icon-wrapper svelte-sxx0n0\">\u003Csvg width=\"100%\" height=\"100%\" stroke-width=\"1.5\" viewBox=\"0 0 24 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\u003Cpath d=\"M12 11.5V16.5\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\u003C/path>\u003Cpath d=\"M12 7.51L12.01 7.49889\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\u003C/path>\u003Cpath d=\"M12 22C17.5228 22 22 17.5228 22 12C22 6.47715 17.5228 2 12 2C6.47715 2 2 6.47715 2 12C2 17.5228 6.47715 22 12 22Z\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\u003C/path>\u003C/svg>\u003C/div>\n\tThis is a Svelte component inside a Markdown file!\n\n\u003C/div>\n\u003Ch2 id=\"processing\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#processing\">\u003Cspan>#\u003C/span>\u003C/a>Processing\u003C/h2>\n\u003Cp>Besides the blog post page itself, the blog posts can be displayed in other places, such as the \u003Ccode>/blog\u003C/code> page, which lists all blog posts, and the \u003Ccode>&lt;RecentPosts&gt;\u003C/code> component, used in the home page.\u003C/p>\n\u003Cp>To be able to do that, posts are processed in the \u003Ccode>src/lib/data/blog-posts/index.ts\u003C/code> file. That file imports the blog post files and processes them, so we’re able to use some of the post’s metadata to list them. For example, we get the post’s title, cover image, and calculate the reading time based on its content, so that information is displayed in the blog post cards in the \u003Ccode>/blog\u003C/code> page.\u003C/p>\n\u003Cp>There is also some basic logic to get related posts based on a post’s tags. The logic should be straightforward enough to modify it to your needs.\u003C/p>\n\u003Ch2 id=\"creating-a-new-post\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#creating-a-new-post\">\u003Cspan>#\u003C/span>\u003C/a>Creating a new post\u003C/h2>\n\u003Cp>To create a new post, create a new folder inside the \u003Ccode>src/routes/(blog-article)\u003C/code> folder, and inside it, create a \u003Ccode>+page.md\u003C/code> file. The folder name will be used as the post’s URL slug, so make sure it’s a valid URL slug.\u003C/p>\n\u003Cp>Inside the \u003Ccode>+page.md\u003C/code> file, you must start with the front matter, which is a YAML-like syntax that is used to define metadata for the post. The front matter must be the first thing in the file, and must be separated from the rest of the content by three dashes (\u003Ccode>---\u003C/code>). An example of a front matter is:\u003C/p>\n\u003Cdiv class=\"code-block svelte-1pkpsrg\">\n\t\u003Cdiv class=\"lang svelte-1pkpsrg\">markdown\u003C/div>\n\t\u003Cpre class=\"language-md\">\u003C!-- HTML_TAG_START -->\u003Ccode class=\"language-md\">\u003Cspan class=\"token front-matter-block\">\u003Cspan class=\"token punctuation\">---\u003C/span>\n\u003Cspan class=\"token front-matter yaml language-yaml\">slug: my-new-blog-post\ntitle: My New Blog Post\ndate: 2023-04-22T20:45:25.350Z\nexcerpt: A short description of the post\ncoverImage: /images/posts/cover-image.jpg\ntags:\n  - Example\u003C/span>\n\u003Cspan class=\"token punctuation\">---\u003C/span>\u003C/span>\u003C/code>\u003C!-- HTML_TAG_END -->\u003C/pre>\n\u003C/div>\n\u003Ch2 id=\"managing-blog-posts\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#managing-blog-posts\">\u003Cspan>#\u003C/span>\u003C/a>Managing blog posts\u003C/h2>\n\u003Cp>I highly recommend the \u003Ca href=\"https://frontmatter.codes/\" rel=\"nofollow\">Front Matter VS Code extension\u003C/a> to manage blog posts. It gives you a nice CMS-like UI to manage the front matter of all blog posts, as well as a preview of their content. It is, of course, optional, and you can manage everything directly in the Markdown files if you prefer.\u003C/p>\n\u003Cimg src=\"/images/posts/frontmatter-preview-dashboard.png\" alt=\"Screenshot of the Front Matter VS Code extension, showing the dashboard with all posts\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1ykl0dj full-bleed\">\n\u003Cimg src=\"/images/posts/frontmatter-preview-edit.png\" alt=\"Screenshot of the Front Matter VS Code extension, showing the post editing UI\" loading=\"lazy\" decoding=\"async\" class=\"svelte-1ykl0dj full-bleed\">\n\u003Ch2 id=\"rss\">\u003Ca class=\"heading-link\" title=\"Permalink\" aria-hidden=\"true\" href=\"#rss\">\u003Cspan>#\u003C/span>\u003C/a>RSS\u003C/h2>\n\u003Cp>This template automatically generates a RSS feed of your blog posts. It is generated in the \u003Ccode>src/routes/rss.xml/+server.ts\u003C/code> file, and it is available at the \u003Ccode>/rss.xml\u003C/code> URL.\u003C/p>","3 min read",{"slug":70,"title":71,"date":72,"excerpt":62,"coverImage":73,"tags":74,"keywords":75,"html":76,"readingTime":77,"relatedPosts":90},[91,92,93],{"slug":59,"title":60,"date":61,"excerpt":62,"coverImage":63,"tags":64,"keywords":66,"html":67,"readingTime":68},{"slug":41,"title":42,"date":43,"excerpt":44,"coverImage":45,"tags":46,"keywords":49,"html":55,"readingTime":56},{"title":79,"slug":80,"coverImage":81,"date":82,"excerpt":83,"hidden":84,"tags":85,"html":87,"readingTime":88},{"slug":59,"title":60,"date":61,"excerpt":62,"coverImage":63,"tags":64,"keywords":66,"html":67,"readingTime":68,"relatedPosts":95},[96,97,98],{"slug":70,"title":71,"date":72,"excerpt":62,"coverImage":73,"tags":74,"keywords":75,"html":76,"readingTime":77},{"slug":41,"title":42,"date":43,"excerpt":44,"coverImage":45,"tags":46,"keywords":49,"html":55,"readingTime":56},{"title":79,"slug":80,"coverImage":81,"date":82,"excerpt":83,"hidden":84,"tags":85,"html":87,"readingTime":88},[100,105,110,115,120],{"name":101,"position":102,"quote":103,"image":104},"Matthew Ziebarth","CTO and Cofounder, \u003Ca href=\"https://adaapp.com\" target=\"_blank\" rel=\"nofollow noopener\">Ada Growth\u003C/a>","Prompt Dress completely solved my issues with saving and organizing my prompts in text files.","images/social-proof/matthew.jpg",{"name":106,"position":107,"quote":108,"image":109},"Andreas Ebner","Partner, Immobiliaris","With Prompt Dress I created and maintained powerful prompts for writing ad texts, and I always have them ready in my browser.","images/social-proof/andi.jpg",{"name":111,"position":112,"quote":113,"image":114},"Heorhii Teryaev","devOps Engineer, Seatti","It's where I keep all my prompts. It has everything I need while not being in the way.","images/social-proof/gosha.jpg",{"name":116,"position":117,"quote":118,"image":119},"Alexandra Kim","Founder and CEO, \u003Ca href=\"https://www.themebloom.com/\" target=\"_blank\" rel=\"nofollow noopener\">MeBloom\u003C/a>","It takes a bit of convincing and fine-tuning before we get the tone for our copies just right. Using Prompt Dress, we never have to look far for the prompts we know are working.","images/social-proof/sasha.jpg",{"name":121,"position":122,"quote":123,"image":124},"GPT-4","LLM, \u003Ca href=\"https://openai.com/\" target=\"_blank\" rel=\"nofollow noopener\">OpenAI\u003C/a>","Absolutely, crafting a quote that conveys social proof for your web app can help build trust and demonstrate value to prospective users. Here are a few general quotes that you might find useful...","images/social-proof/chatgpt.png"],"uses":{}}]}
